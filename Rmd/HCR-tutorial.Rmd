---
title: "Developing Harvest Control Rules for Alberta Walleye Fisheries"
author: "Christopher L. Cahill & Carl J. Walters"
date: "14/03/2022"
output:
  html_document: default
  pdf_document: default
highlight: tango
urlcolor: blue
---
# IN PROGRESS--Cahill must finish by March 31

## TODO
- parellel ordering of MAY / HARA
- Carl's point about including precautionary rules
- proofread -- check citations

## Purpose 
The purpose of this tutorial is to develop a management strategy evaluation or simulation framework that can be used to evaluate harvest control rules for any of the Alberta Walleye fisheries assessed in Cahill et al. 2021 using either yield or catch-based objectives. 

## Goals
- Provide readers with some background on the development of policies for fisheries management
- Understand what a harvest control rule is and why such rules is useful for managing natural resources
- Understand how the code is pulling results from the stock assessments and using these as inputs into our harvest control rule simulation program
- Work through the model structure of the harvest control rule simulator, including calculations of maximum average yield and HARA utility 
- Develop intuition for the catch and release mortality components of the simulation model
- Understand the tabular or grid search approach to "optimizing" simple linear harvest control rules

## Background 
Harvest control rules are agreed-upon, transparent, and repeatable mathematical equations that help managers alter harvest levels in response to changes in stock size to achieve some explicit goal.  Changes in population size may be due to either environmental stochasticity or the effects of fishing. In Alberta, harvest control rules may be particularly useful for informing special harvest license allocations given some agreed upon and explicit management objectives and Fall Walleye Index Netting (FWIN) survey data. The development of explicit harvesting rules appears important, because a finding of Cahill et al. 2021 was that many Alberta Walleye lakes appeared underharvested relative to common fisheries reference points. 

There exists a rich history of using harvest control rules or feedback policies to design effective fisheries management systems, and there are at least three key references that will help you better understand many of the issues that I am about to discuss in this tutorial. These references are:

1. Walters 1986, chapter on feedback policies
2. Hilborn and Walters 1992, chapter on Designing Effective Fisheries Management Systems
3. Quinn and Deriso 1999
4. Walters and Martell 2001, chapters 2-4

These are solid sources of information on this topic. In general, you will find that it is much more difficult to design effective fisheries management systems and harvest control rules than it is to simply assess a particular fishery.  This is because what we are actually doing is attempting to design a control rule (a "controller") for a nonlinear dynamical system.  

## But first, a nonmathematical description of the problem that we would share with Grandma

You can think of this harvest control rule problem like trying to design an autopilot system (or a control rule or policy) that keeps a plane air born--our goal in this case is to create a mathematical rule that relates measurements from the environment taken by sensors (altitude, jet speed, wind speed, wind direction, etc.) to actions the plane can take to alter its course of movement (increase speed, decrease speed, turn left/right/up/down). The point here that really matters is that we are trying to design a feedback policy, which relates where we are (in the environment) to what we want to achieve.  

In this case, the "environment" simply refers to the physical equations governing the flight of a plane. In our fisheries situation, it refers to all of the equations and biological or ecological processes describing the dynamics of a harvested population.  Whereas there are sensors on the plane which tell us "where" the plane is and what the state of the environment is outside of that plane, we use surveys to determine the state of a population in fish and wildlife management settings. 

In the oversimplified case of the autopilot system, the goal is not to crash.  Intuitively, this might mean that a good feedback policy for the plane try to orient to the right if the wind pushes it to the left, and maneuver upward if it were decreasing in altitude for whatever reason.  In a fishery, the goal might be to let the stock size recover if it has been overfished, or to harvest more if the stock size were high.

## Harvesting theory, dynamic programming, and optimal solutions

A great deal of theoretical work on optimal harvesting strategies for dynamic populations shows that optimal policies generally decrease harvest rate when population size declines, and increase it as population size increases. These findings have often come from dynamic programming solutions, and the solutions for these particular problems are often simple functions of harvestable abundance or biomass.  This finding appears general and was surprising--it was generally believed that complex policies would be required to manage complex ecological systems.  However, a great deal of work on harvesting theory during the 1970-80s showed that simple policies performed well or were even optimal in many situations (e.g., Walters 1975; Walters and Hilborn 1978; Mangel XXXX; Clark XXXX; Moxnes XXXX).  

A limitation of dynamic programming and related methods is that these approaches can only be applied to relatively simple models and management objectives.  The age-structured Bayesian Estimation of Recruitment Trends in Alberta ('BERTA) model is too complex to use with such methods. Thus, we will instead use a simulation technique known as optimization in policy space to find good harvest control rules (see methods in Moxnes XXXX; Edwards and Dankel 20XX) for our models.

We briefly hit on this above, but there is one more difficulty facing us and that is that there are multiple (often conflicting) objectives in resource management. We discuss two such conflicting objectives in the next section, but note that our management strategy simulation approach can cope with this issue quite nicely. 

## On the need for explicit objectives

In the above toy airplane autopilot example, we wouldn't get very far if we didn't agree up front that the goal was to keep the plane flying within some (acceptable) flight parameters.  The same is true for designing harvest control rules for renewable resources: if we do not agree upon how to manage a population a priori, we will not get very far.  If we want to design effective fisheries management systems, we at least need to agree upon how best to manage those fisheries. This is easier said than done, and individuals have dedicated their entire careers toward developing structured decision making programs to meaningfully engage relevant stakeholders and develop such objectives.

For Alberta Walleye, there are presently no agreed upon *explicit* objectives for fisheries management. Believe it or not, this is pretty common for many fisheries. Thus, we will introduce two concepts--Maximum Average Yield (MAY) and Hyperbolic Absolute Risk Aversion Utility (HARA)--as starting points for Alberta Walleye fisheries. Ideally, objectives should be set through a structured decision making process (see Edwards and Dankel 20XX). It is unlikely that Cahill and Walters (or any manager or researcher for that matter) should be setting the objectives for Alberta fisheries; instead, we hope to demonstrate how Alberta Walleye fisheries could be managed given some agreed upon objectives.  

Our approach here is to specify two provisional conflicting objectives, and then later we will simulate across a range of policy options to find policies that do well in our simulations given these objectives.  We discuss both of these objectives in the following sections.

## Maximum Average Yield (MAY) objective 

Maximum Average Yield is the stochastic analog of Maximum Sustainable Yield (MSY). In a harvested population, this is the highest yield that can be taken on average from a population experiencing average environmental conditions.  While there are many criticisms of MSY or MAY (e.g., Larkin 19XX), in general these yield-maximization policies demonstrate how much yield can be achieved from a given fishery if a MAY maximizing objective (and corresponding policy) was adopted. When you simulate yield maximization policies or attempt to solve this problem using dynamic programming, what you find is that the optimal policy often is some type of fixed "escapement" policy.  That is, there is a lower limit reference point below which no harvesting occurs, and above this lower limit reference point you tend to harvest at a rate near $F_{msy}$, or the instantaneous fishing mortality rate thought to achieve MSY. 

While such policies maximize the average yield that can be taken from dynamic and uncertain or even unpredictable fisheries, they have the downside that they result in increased variability to harvesters in terms of fisheries closures as stock size drops below a fixed lower limit reference point.  Remember, if the stock drops below the lower limit reference point the MAY policy shuts off harvesting completely. 

## Hyperbolic Absolute Risk Aversion (HARA) utility objective

Hyperbolic Absolute Risk Aversion for catch (herein-after, HARA) is an objective that values consistency in catch through time from the perspective of a harvester.  It is critical to include risk-averse utility for catch as a performance measure representing the interests of stakeholders and Indigenous harvesters so that we explicitly consider stakeholder interests. The simplest way to do this is to calculate utility each year with a hyperbolic absolute risk averse utility function, which boils down to the following equation 

$$ utility_t = catch_t^{pp} $$

In this case, $catch_t$ is simply yield in year $t$, and the power term $pp$ is a risk aversion parameter that for most people is near 0.3-0.5. You can empirically assess $pp$ by asking people to choose between two income options: a 50:50 gamble between 0 and 100,000 dollars, or a sure income of around 30,000 dollars. The expected value of the income outcome of the 50:50 gamble is 50,000 (i.e., 1/2 * 100,000), but most people will choose a guaranteed income of around 30,000 dollars vs. the 50:50 chance at winning the 100,000 dollars (myself included).  

This scenario implies $pp = 0.57$.  You can calculate someone's $pp$ by asking how much guaranteed reward (catch, income) they would need to receive before they were unwilling to take the "unsure" bet--so if you said your $X = 20,000$ dollars (or catch of fish), your $pp$ would be 

$$pp = ln(0.5) / (ln(20) - ln(100)) = 0.43$$

And note that we have substituted "20" for 20,000 and "100" for 100,000 because the math works out to be the same.  

When we ask fishermen what $X$ they would need to not fish, typical answers have been in the 20,000-30,000 range, i.e. having some income or catch is much more important than maximizing average income if that means having highly variable income or catch. When framed this way, HARA utility is a powerful tool for capturing aversion to variability in catch. 

When HARA utility is maximized as an objective, it tends to do two things relative to the MAY objective discussed above.  First, the HARA objective tends to shift the lower limit reference point toward zero.  This is because if we "shut off" fishing we lose a great deal of utility.  The second thing that this objective tends to do when you undertake formal optimization (i.e., dynamic programming) is that it generally speaking lowers the rate at which you increase harvest as stock size increases.  For now you have to take my word on this, but we will demonstrate this via simulation later on. 

## Simulating some simple (fake) MAY vs. HARA policies

We picked these two objectives (MAY, HARA) to represent management tradeoffs (see Walters and Martell 2001).  MAY represents maximum yield that say a corporation exploiting many populations at once might desire to maximize expected catch from a collection of populations, while HARA represents a better policy for a risk averse fisher or angler. To harvest under a harvest control rule that was developed to achieve MSY or MAY is to concede that a fishery will need to be closed for potentially many years if stock sizes drop below the lower limit reference point. This is particularly problematic for fisheries with highly variable recruitment dynamics like Alberta Walleye, as closures might be triggered simply due to natural variability if we are not careful.  Conversely, to harvest under a HARA objective and corresponding policy is to harvest at a lower rate but to continue to harvest when biomass drops below the lower limit reference point required to achieve MAY. These are key lessons from theoretical studies of harvested populations (e.g., see Walters and Hilborn 1976; 1978; Walters 1986), and we will demonstrate these principles in excruciating detail as we proceed with our Alberta Walleye example.

If you are a visual learner, you might have an easier time with the following hypothetical depiction of fixed escapement MAY vs. a HARA policy.  

Let's load some packages: 

```{r echo=T, results='hide', message = FALSE, warning=FALSE}
# packages
library(tidyverse)
```

And then simulate and plot some dead simple harvest control rules (I made these up): 

```{r, , message = FALSE, warning=FALSE}
vB <- seq(from=0.1, to =100, length.out = 100) # biomass vulnerable to fishing
b_lrp <- c(0, 30) # lower limit reference point
c_slopes <- c(0.2, 1) # slope of harvest control rule

TAC_HARA <-  c_slopes[1] * (vB - b_lrp[1]) # total allowable catch HARA 
U_HARA <- TAC_HARA / vB # exploitation rate HARA

TAC_MAY <-  c_slopes[2] * (vB - b_lrp[2])
TAC_MAY[which(TAC_MAY < 0 )] <- NA # Set negative values to NA (don't harvest below blrp)
U_MAY <- TAC_MAY / vB 

# make a big data frame
data_HARA <- data.frame(vB, TAC = TAC_HARA,  U = U_HARA, policy = "HARA")
data_MAY <- data.frame(vB, TAC = TAC_MAY,  U = U_MAY, policy = "MAY")
data <- rbind(data_HARA, data_MAY)

data %>%
  ggplot(aes(x=vB, y = TAC, group = policy))+
  geom_line(aes(linetype = policy), lwd = 1.25) +
  ylab("Total allowable catch (kg/ha)") + 
  xlab("Biomass of finned critters vulnerable to fishing (kg/ha)") + 
  ggtitle("Hypothetical HCRs: Total Allowable Catch vs. Vulnerable Biomass")

``` 

In this example, there is a lower limit reference point $b_{lrp}$ and a slope at which you increase harvest as stock size increases ($c_{slope}$ in the code). Next we can plot exploitation rate as a function of stock size for these simple examples using this code: 

```{r, , message = FALSE, warning=FALSE}

data %>%
  ggplot(aes(x=vB, y = U, group = policy))+
  geom_line(aes(linetype = policy), lwd = 1.25) +
  ylab("Exploitation rate (TAC / vulnerable Biomass)") + 
  xlab("Biomass of finned critters vulnerable to fishing (kg/ha)") + 
  ggtitle("Hypothetical HCRs: Exploitation Rate vs. Vulnerable Biomass")
```

Think about these last two plots a bit--it is important to wrap your head around what this is showing you. Most of the harvest control rule simulation script that we will go through below is shifting the intercepts and slopes of these lines from Figure 1 to find simple linear policies that maximize specific objectives like MAY or HARA utility. 

## Thinking through one more harvest control rule

While the polices above arise from explicit objectives and dynamic programming solutions (again, take my word for it), we will take this opportunity to work through one more policy that you might encounter in fisheries.  This is DFO's so-called precautionary harvest control rule (DFO XXXX), which is based on work from Restrepo XXXX.  This policy has been adopted for fisheries throughout Canada (and regardless of the management objectives of those fisheries).  The DFO policy specifies a rectilinear harvest control rule, and while it is often unclear what is specifically supposed to be precautionary about this rule we will simulate it anyway to show you what it is doing. 

The DFO policy increases exploitation rate from zero to $U_{MSY}$ as biomass increases from a lower limit reference point to an upper limit reference point.  These reference points are typically set at $0.4 \cdot B_{MSY}$ and $0.8 \cdot B_{MSY}$.  Note that $U_{MSY}$ and $B_{MSY}$ typically need to be estimated in an assessment model.  

In our simple example, we will say $U_{MSY}$ = 0.2, and that $B_{MSY}$ = 30 kg/ha. Thus, we would specify the DFO harvest control rule as follows:

```{r, , message = FALSE, warning=FALSE}

U_MSY <- 0.2 
B_MSY <- 30
b_lrp <- 0.4*B_MSY
u_lrp <- 0.8*B_MSY

U_DFO <- U_MSY * (vB - b_lrp) / (u_lrp - b_lrp)
U_DFO[which(U_DFO < 0 )] <- NA # Set negative values to NA 
U_DFO[which(U_DFO > U_MSY)] <- U_MSY # Set negative values to NA 

# calculate the TAC as U*vB
data_DFO <- data.frame(vB, TAC = U_DFO*vB,  U = U_DFO, policy = "DFO")
data <- rbind(data, data_DFO)
```

We can then plot it like we did before: 

```{r, message = FALSE, warning=FALSE}
data %>%
  filter(policy == "DFO") %>%
  ggplot(aes(x=vB, y = TAC, group = policy))+
  geom_line(aes(linetype = policy), lwd = 1.25) +
  ylab("Total allowable catch (kg/ha)") + 
  xlab("Biomass of finned critters vulnerable to fishing (kg/ha)") + 
  ggtitle("Hypothetical HCRs: Total Allowable Catch vs. Vulnerable Biomass")

```

This plot is admittedly a bit weird looking, but that's just how this policy plays itself out. We can also plot the exploitation rate vs. vulnerable biomass for this policy as well: 

```{r, message = FALSE, warning=FALSE}

data %>%
  filter(policy == "DFO") %>%
  ggplot(aes(x=vB, y = U, group = policy))+
  geom_line(aes(linetype = policy), lwd = 1.25) +
  ylab("Exploitation rate (TAC / vulnerable Biomass)") + 
  xlab("Biomass of finned critters vulnerable to fishing (kg/ha)") + 
  ggtitle("Hypothetical HCRs: Exploitation Rate vs. Vulnerable Biomass")

```

And you can see where the name "rectilinear harvest control rule" comes from. So in this example, there's no harvest below some lower limit reference point, and then we "cap" the maximum harvest rate at $U_{MSY}$. 

Remember, this is the harvest control rule used for most fisheries managed via a harvest control rule by DFO. What does this rectilinear rule imply from a HARA or MAY perspective?  What does it imply for other objectives? 

## How do we use our Bayesian assessment models to inform harvest control rules? 

Before we begin working through the harvest control rule simulation script, we need to understand what we currently have in terms of the analyses we have completed up to this point.  In previous tutorials we have estimated a straightforward age-structured stock assessment model for Alberta Walleye.  We have saved the posteriors from these model fits for each lake in their own .rdata files in the `fits` folder on the Github for this project. 

The posteriors that we have saved capture uncertainty in Walleye population dynamics given our model structure, priors, and data for a given lake.  Thus, we can use results from these assessments to initialize a harvest control rule simulation, and run these simulations for many random draws from the posterior to characterize uncertainty in our policy rule development.  We will undertake a specific type of management strategy evaluation known as retrospective harvest control rule simulation. All this means is that once we initialize our simulation model using our stock assessment results, we will repeat recruitment anomaly sequences $w_t$ some number of times into the future. We will play around with this a bit, but the primary goal here is to develop harvest policies that are robust to the recruitment dynamics that were estimated in Cahill et al. 2021. 

Conceptually, the way we will do this is as follows: 

1. Initialize our population dynamics simulation model using assessment model results for some lake given the survey data.
2. Project this age-structured population dynamics model into the future using (nearly) the same equations as in Cahill et al. 2021.
3. For each policy we want to test the performance of, we initialize our simulation model using one draw of the posterior, run the simulation forward in time while implementing a specific policy, and record performance in terms of yield achieved or HARA utility.
4. Repeat this process many times (e.g., 30-1000 random posterior draws) so as to explicitly characterize uncertainty in the biological dynamics of walleye populations during the development of our policies (harvest control rules). 
5. Look across all policies we tested, and look up the policies that maximized average yield or HARA utility, respectively.  
7. Go for a long run and drink tasty beer, never think about designing controllers for nonlinear dynamical systems again.
8. Upon recovering, go back and see how well the DFO rule works for Alberta Walleye.

This will get a little tedious as we work through things, but the key point to remember here is that we are trying to create a rule for managers that says "if our objective is x and our net catch is y, how many fish should we allocate in year t?"  We will relax a variety of assumptions around this (assessment interval, survey variability to address imperfect observability of system state, and catch and release mortality which is uncontrolled because effort is not controlled in these systems), but the main point is we are trying to design an equation that helps folks achieve some objective(s) given a net catch.

Additionally, while we are only going to use two conflicting objectives, it is straightforward to do this for any specific objective(s) you want. Phrased differently, if you have explicit multi-criteria objectives and some weighting scheme you could easily adapt this script to test the performance of such an objective.

## The `hrc.R` simulation script

The `hcr.R` script works like the `run.R` script in our earlier tutorials.  The `get_hcr()` function takes in some inputs, reads in a specific Bayesian model fit from a given lake, extracts the relevant stuff that we need to parameterize an age structured model, and then runs our simulations forward in time for some number of draws and records performance of that simulation.  It then saves the simulation output as a .rds file with a unique file name (based on whatever simulation choices you chose) in a `sim/` folder.  The full function is available here:  

<https://github.com/ChrisFishCahill/managing-irf-complexity/blob/main/r-code/hcr.R#L17-L359>

This function was primarily developed to test the simple linear harvest control rules (see MAY vs. HARA examples above), but it can also be used to test the DFO-style rectilinear harvest control rule.  For now, we'll ignore the rectilinear rule entirely and just focus on the simple linear rules.  Once we work through the linear harvest control rules and get a handle on how this works, we'll loop back at the end of this tutorial deal with the rectilinear policy. Eventually we will be able to compare the performance of the linear vs. rectilinear harvest control rules for Alberta Walleye fisheries.

Before we start jumping through this function line by line, I want you to look at the following lines of code below the function here.  

<https://github.com/ChrisFishCahill/managing-irf-complexity/blob/main/r-code/hcr.R#L361-L432>

Please note you don't have to know what all of this is doing yet.  The main reason to show you is that there is eventually going to be stuff in our R environment (like a bunch of simulation control parameters and our Bayesian model fits in list form) that our `get_hcr()` function is going to interact with.  If I didn't show you this up front, you might get confused as we work through the function. 

With that in mind, the first chunk of code in `get_hcr()` is the following: 

```{r, eval=FALSE}
get_hcr <- function(which_lake = "lac_ste._anne", ass_int = 1,
                    sd_survey = 0.05, d_mort = 0.3,
                    rule = c("linear", "precautionary")) {
# many more lines of code...

```

These are inputs you can change depending on your desires.  The arguments that you can play around with are:

- `which_lake`, a string that specifies the lake name that you want to run. This needs to be lowercase and have underscores in place of spaces.
- `ass_int`, describes the interval at which we will assess the fishery.  
- `sd_survey`, describes the amount of noise in the survey that we base our harvest control rules off of.
- `d_mort`, the discard mortality rate for released fish. 
- `rule`, specifies between linear or rectilinear harvest control rules.

The next few lines of the function specify a bunch of additional simulation parameters: 

```{r, eval=FALSE}
  #--------------------------------------------------------------------
  # initialize stuff
  #--------------------------------------------------------------------
  n_draws <- hcr_pars$n_draws
  n_repeats <- hcr_pars$n_repeats
  retro_initial_yr <- hcr_pars$retro_initial_yr
  retro_terminal_yr <- hcr_pars$retro_terminal_yr
  n_sim_yrs <- hcr_pars$n_sim_yrs
  ages <- hcr_pars$ages
  n_ages <- length(ages)
  initial_yr <- hcr_pars$initial_yr
  initial_yr_minus_one <- hcr_pars$initial_yr_minus_one
  ret_a <- hcr_pars$ret_a
  Ut_overall <- hcr_pars$Ut_overall
  sbo_prop <- hcr_pars$sbo_prop
  rho <- hcr_pars$rho
  sd_wt <- hcr_pars$sd_wt
  psi_wt <- hcr_pars$psi_wt
  n_historical_yrs <- length(retro_initial_yr:retro_terminal_yr)
  grid_size <- hcr_pars$grid_size
```

These lines of code are looking up values from a tagged list called `hcr_pars`. I set the values in this function later on in the script in these lines: 

<https://github.com/ChrisFishCahill/managing-irf-complexity/blob/main/r-code/hcr.R#L386-L403>

You can change these if you want, but you'll notice that I haven't put these explicitly in the function call for `get_hcr()`. I did this because you should probably know what you are doing if you want to change these parameters.  This might seem annoying, but the reason I did this is because if I needed to change any of these values I needed all the following code in this function to update automatically.  This was the best way I could think to do that, though I'm sure there are other (and perhaps more elegant) solutions. 

The `hcr_pars` list determines the following things: 

-`n_draws` is the number of draws from the posterior that you want to simulate across.

-`n_repeats` is the number of times you want to repeat your recruitment anomaly sequences into the future.

-`retro_initial_yr` a stupid index value that helps chris keep the initial year of the model run straight.

-`retro_terminal_yr` a stuider index value that helps chris keep the terminal year of the model run straight.

-`n_sim_yrs` how many years between initial and terminal year multiplied by n_repeats.  Total length of simulation.

-`ages` ages of fish in years. this is a vector. 

-`n_ages` you guessed it: the number of ages in the `ages` vector.

-`initial_yr` the initial year of the BERTA model (1980).

-`initial_yr_minus_one` you guessed it, this corresponds to 1979.

-`ret_a` this is the proportion of critters that are retained at age if they are caught by anglers.

-`Ut_overall` this is a cap on the maximum exploitation rate that angling can impose on a fishery.

-`sbo_prop` this is a term that manipulates one of the performance measures in terms of whether a population fall below some proportion. 

I don't want you to worry too much about these for the moment.  You may not like these initial values.  So be it.  The point of coding it this way is so that we can loop through and run many different simulations with many different input parameters.

The next code block is just taking the `which_lake` string, and using it to grab the appropriate Bayesian model fit (which eventually will be stored in our R environment from the fits folds):

```{r, eval=FALSE}
#--------------------------------------------------------------------
# subset lake-specific posterior from all fits
#--------------------------------------------------------------------
lake_str <- gsub(" ", "_", which_lake)
fit_idx <- grep(lake_str, names(fits))
fit <- fits[[fit_idx]]
rec_ctl <- ifelse(grepl("bh", names(fits)[fit_idx]), "bh", "ricker")
```

The first line makes sure there are no spaces in the variable `which_lake`.  The next line determines which of the fits (in the R environment) corresponds to the `which_lake` we wanted to run the simulation for. We then read in the fit corresponding to our lake, and then declare a control variable  called `rec_ctl` indicating whether the fitted Bayesian model used a Beverton-Holt (i.e., "bh") or Ricker stock-recruit model (i.e., "ricker"). Sweet. 

The next ten or so lines are used for the rectilinear harvest control rule, and so we will ignore this for now.  Note this code is only triggered when rule = "rectilinear". 

https://github.com/ChrisFishCahill/managing-irf-complexity/blob/main/r-code/hcr.R#L49-L62




And for now I will just jump into what it is actually doing. There are basically two types of inputs in this function.  The first are the things that you can play around with and are listed as 



This function takes in four main 


that we first write a function that does a bunch of calculations and then saves an appropriately named output file as a `.rds`. This function is called `get_hcr.R`, and it takes in the following 


## junk writing garbage can 

A bewildering array of harvest control rule shapes and forms exists (see review in Deroba and Bence 20XX). These rules relate how much should be allocated for harvest relative to the biomass or number of critters vulnerable to harvesting.  Here is an example of a simple harvest control rule: 



Early optimization work on harvesting theory shows that optimal rules given simple models and single objectives typically decrease harvest rate as population size decreases and increase harvest rate as population size increases (citations).  It doesn't have to be complicated.  Many rules, such as the generic rule proposed in Fisheries and Oceans Canada (DFO) 20XX, suggest that rectilinear harvest control rules are "precautionary." However, what *specifically* is precautionary about such rules is rarely 

rarely specify what is precautionary about the specific rule beyond references to Restrepo XXXX. 

(and 

Given these considerations, we will primarily focus on the simulation evaluation of simple linear harvest control rules. If it isn't broke, don't fix it sort of thing.







and repeat this process many times (e.g., 30-100 random draws).  Each time we record the performance of a policy

each of some number (e.g., say 30 or 100) of random values from our assessment posteriors, run our model into the future. 













## Resources: 

Cahill et al. 2021 CJFAS. 

Department of Fisheries and Oceans 2006.  A harvest strategy compliant with the precautionary approach. 

Deroba and Bence XXXX.  Harvest control rules.

Edwards and Dankel 20XX.  Fisheries Management Science.

Gelman et al. 2013. Bayesian Data Analsyis.

Larkin. Epitaph on Maximum Sustainable Yield.

Moxnes XXXX. 

Walters and Hilborn 1976. Adaptive control of fishing systems. 

Walters and Hilborn 1978. Ecological optimization and adaptive management. 

Hilborn and Walters 1992. Quantitative Fisheries Stock Assessment.

Walters 1986.  Adaptive Management of Renewable Resources.

Walters and Martell. 2001. Fisheries Ecology and Management. 
